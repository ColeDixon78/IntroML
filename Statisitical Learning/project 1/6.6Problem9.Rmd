---
title: "6.6 Problem 9"
output: html_notebook
---

#### Part a
```{r}
library(ISLR2)
attach(College)
head(College)
set.seed(1)
```

```{r}
train = sample(c(TRUE,FALSE),nrow(College),replace = TRUE)
test = (!train)
```

#### part b

```{r}
lm.fit = lm(Apps ~ ., data = College[train, ])
summary(lm.fit)
lm.predictions = predict(lm.fit, College[test, ])
lm.test_mse <- mean((College$Apps[test] - lm.predictions)^2)
lm.test_mse
```

The mean squared error is 984743.1 for the standard linear regression model.

#### part c

```{r}
library(glmnet)
x <- model.matrix(Apps ~ ., College[train, ])[, -1]
y <- College$Apps[train]
```

```{r}
cv.out <- cv.glmnet(x,y, alpha = 0)
plot(cv.out)
best.lambda <- cv.out$lambda.min
best.lambda
```
```{r}
ridge.mod <- glmnet(x,y,alpha = 0)
ridge.predict <- predict(ridge.mod, s = best.lambda, newx = model.matrix(Apps ~ ., College[test, ])[, -1])
ridge.mse = mean((College$Apps[test] - ridge.predict)^2)
ridge.mse
```

The test mse for the ridge model is 940970.9

#### part d

```{r}
lasso.mod <- glmnet(x,y,alpha = 1)
cv.out <- cv.glmnet(x,y)
plot(cv.out)
best.lambda <- cv.out$lambda.min
best.lambda
```

```{r}
lasso.predict <- predict(lasso.mod, s = best.lambda, newx = model.matrix(Apps ~., College[test,])[, -1])
lasso.mse = mean((College$Apps[test] - lasso.predict)^2)
lasso.mse
lasso.coefi <- predict(lasso.mod, type = "coefficients", s= best.lambda)
lasso.coefi[lasso.coefi != 0]
```

Test mse for the lasso model is 956469.3 with 15 non-zero coefficients.

#### part e

```{r}
library(pls)
pcr.fit <- pcr(Apps ~ ., data = College[train, ], scale = TRUE, validation = "CV")
summary(pcr.fit)
validationplot(pcr.fit,val.type = "MSEP")
```
```{r}
pcr.predict = predict(pcr.fit,College[test, ], ncomp = 17)
pcr.mse = mean((College$Apps[test] - pcr.predict)^2)
pcr.mse
```
The test MSE is 984743.1 for PCR model with M = 17

#### part f
```{r}
pls.fit <- plsr(Apps ~ ., data = College[train, ], scale = TRUE, validation = "CV")
summary(pls.fit)
validationplot(pls.fit,val.type = "MSEP")
```
```{r}
pls.predict = predict(pls.fit,College[test, ], ncomp = 13)
pls.mse = mean((College$Apps[test] - pls.predict)^2)
pls.mse
```

The test MSE is 990526.1 for PLS model with M = 13

#### part g
The test MSEs for the different models are all competetive with each other, but the the ridge regression model performed best as it had the lowest test MSE. The models are able to predict Apps pretty well considering that the adjusted R squared statistic for our baseline standard linear regression model was .927, and all of the following models had lower or slightly higher test MSEs.