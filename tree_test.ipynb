{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gains': {'citric acid': 0.11644331159277607, 'residual sugar': 0.23005216511474283, 'pH': 0.0964537780661524, 'sulphates': 0.17530932492038187, 'alcohol': 0.00873819106050372}, 'entropy': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from chefboost.training import Training\n",
    "from sklearn import datasets\n",
    "df = pd.read_csv(\"wine_dataset.csv\")\n",
    "df.rename(columns={\"type\":\"Decision\"},inplace=True)\n",
    "config = {\"algorithm\":\"ID3\"}\n",
    "gains = Training.findGains(df,config)\n",
    "print(gains)\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame({\"data\":[0,0,0,0],\"type\":[\"a\",\"B\",\"a\",\"a\"]})\n",
    "y = pd.DataFrame({\"data\":[1,2,3,4]})\n",
    "data_is_equal = True\n",
    "for key in X.keys():\n",
    "    if len(X[key].unique()) == 1:\n",
    "        continue\n",
    "    else:\n",
    "        data_is_equal = False\n",
    "print(data_is_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99082429 0.76994783 0.90354622 0.82469068 0.99871933]\n",
      "[0.00917571 0.23005217 0.09645378 0.17530932 0.00128067]\n"
     ]
    }
   ],
   "source": [
    "entropy_list = []\n",
    "for key in X.keys():\n",
    "    split = np.mean(X[key])\n",
    "    X_split = X[key] < split\n",
    "    cond_entropy = 0\n",
    "    for value in X_split.unique():\n",
    "        prob_X = X_split.value_counts()[value]/len(X_split)\n",
    "        column = y.keys()[-1]\n",
    "        for label in y[column].unique():\n",
    "            prob_y_cond = (((X_split == value)&(y[column] == label)).value_counts()[True]/len(X_split))\n",
    "            cond_entropy -= prob_y_cond * np.log2(prob_y_cond/prob_X)\n",
    "    entropy_list.append(cond_entropy)\n",
    "arr = np.array(entropy_list)\n",
    "print(arr)\n",
    "print(1-arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = [0,0,0,0,0,0,0,0,0,0]\n",
    "#y = [1,1,1,1,1,1,1,1,1,1]\n",
    "y = [0,1,1,1,1,0]\n",
    "if len(set(y)) == 1:\n",
    "    print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "        def __init__(self,dec_key,dec_val):\n",
    "            self.dec_key = dec_key\n",
    "            self.dec_val = dec_val\n",
    "        def right(self,next):\n",
    "            self.right_branch = next\n",
    "        def left(self,next):\n",
    "            self.left_branch = next\n",
    "        pass\n",
    "class Leaf():\n",
    "    def __init__(self,val):\n",
    "        self.val = val\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_data_entropy(y):\n",
    "    data_entropy = 0\n",
    "    column = y.keys()[-1]\n",
    "    for label in y[column].unique():\n",
    "        print(y[column].value_counts())\n",
    "        label_prob = (y[column].value_counts()[label])/len(y)\n",
    "        data_entropy -= (label_prob) * np.log2(label_prob)\n",
    "    return data_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_conditional_entropy(X,y):\n",
    "    entropy_list = []\n",
    "    for key in X.keys():\n",
    "        split = np.mean(X[key])\n",
    "        X_split = X[key] < split\n",
    "        cond_entropy = 0\n",
    "        for value in X_split.unique():\n",
    "            prob_X = X_split.value_counts()[value]/len(X_split)\n",
    "            column = y.keys()[-1]\n",
    "            for label in y[column].unique():\n",
    "                prob_y_cond = (((X_split == value)&(y[column] == label)).value_counts()[True]/len(X_split))/prob_X\n",
    "                cond_entropy -= prob_X * prob_y_cond * np.log2(prob_y_cond)\n",
    "        entropy_list.append(cond_entropy)\n",
    "    entropy_list = np.array(entropy_list)\n",
    "    return entropy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(X,y):\n",
    "    #calculate entropy of X data set\n",
    "    data_entropy = calculate_data_entropy(y)\n",
    "    #calculate conditional entropy given a split data for each predictor\n",
    "    cond_entropy_array = calculate_conditional_entropy(X,y)\n",
    "    #difference in data set entropy and conditional entropies gives us information gain of each split\n",
    "    information_gain = data_entropy - cond_entropy_array\n",
    "    print(information_gain)\n",
    "    return np.argmax(information_gain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(X,y,impurity_measure = 'entropy'):\n",
    "    print(X.info())\n",
    "    print(y.info())\n",
    "    #check if all labels are the same; return leaf of that value if they are\n",
    "    column = y.keys()[-1]\n",
    "    if len(y[column].unique()) == 1:\n",
    "        return Leaf(y[column][0])\n",
    "    #check if all data values are the same and return most common label if true\n",
    "    data_is_equal = True\n",
    "    for key in X.keys():\n",
    "        if len(X[key].unique()) == 1:\n",
    "            continue\n",
    "        else:\n",
    "            data_is_equal = False\n",
    "    if data_is_equal:\n",
    "        return Leaf(y[column].value_counts()[0])\n",
    "    \n",
    "    #find split with most information gain and split data to left and right branches\n",
    "    else:\n",
    "        split_index = information_gain(X,y)\n",
    "        split_key = X.keys()[split_index]\n",
    "        split_value = np.mean(X[split_key])\n",
    "        branch = Node(split_key,split_value)\n",
    "        branch.right = learn(X[X[split_key] < split_index].reset_index(),y[X[split_key] < split_index].reset_index())\n",
    "        branch.left = learn(X[X[split_key] >= split_index].reset_index(),y[X[split_key] >= split_index].reset_index())\n",
    "        return branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3198 entries, 0 to 3197\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   citric acid     3198 non-null   float64\n",
      " 1   residual sugar  3198 non-null   float64\n",
      " 2   pH              3198 non-null   float64\n",
      " 3   sulphates       3198 non-null   float64\n",
      " 4   alcohol         3198 non-null   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 125.0 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3198 entries, 0 to 3197\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   type    3198 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 25.1 KB\n",
      "None\n",
      "type\n",
      "1    1599\n",
      "0    1599\n",
      "Name: count, dtype: int64\n",
      "type\n",
      "1    1599\n",
      "0    1599\n",
      "Name: count, dtype: int64\n",
      "[0.00917571 0.23005217 0.09645378 0.17530932 0.00128067]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28 entries, 0 to 27\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   index           28 non-null     int64  \n",
      " 1   citric acid     28 non-null     float64\n",
      " 2   residual sugar  28 non-null     float64\n",
      " 3   pH              28 non-null     float64\n",
      " 4   sulphates       28 non-null     float64\n",
      " 5   alcohol         28 non-null     float64\n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 1.4 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28 entries, 0 to 27\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   index   28 non-null     int64\n",
      " 1   type    28 non-null     int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 576.0 bytes\n",
      "None\n",
      "type\n",
      "0    26\n",
      "1     2\n",
      "Name: count, dtype: int64\n",
      "type\n",
      "0    26\n",
      "1     2\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "True",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5846\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.UInt8HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5870\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.UInt8HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m X \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[:,:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m      3\u001b[0m y \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:]\n\u001b[0;32m----> 5\u001b[0m tree \u001b[39m=\u001b[39m learn(X,y)\n",
      "Cell \u001b[0;32mIn[93], line 24\u001b[0m, in \u001b[0;36mlearn\u001b[0;34m(X, y, impurity_measure)\u001b[0m\n\u001b[1;32m     22\u001b[0m split_value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(X[split_key])\n\u001b[1;32m     23\u001b[0m branch \u001b[39m=\u001b[39m Node(split_key,split_value)\n\u001b[0;32m---> 24\u001b[0m branch\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m learn(X[X[split_key] \u001b[39m<\u001b[39;49m split_index]\u001b[39m.\u001b[39;49mreset_index(),y[X[split_key] \u001b[39m<\u001b[39;49m split_index]\u001b[39m.\u001b[39;49mreset_index())\n\u001b[1;32m     25\u001b[0m branch\u001b[39m.\u001b[39mleft \u001b[39m=\u001b[39m learn(X[X[split_key] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m split_index]\u001b[39m.\u001b[39mreset_index(),y[X[split_key] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m split_index]\u001b[39m.\u001b[39mreset_index())\n\u001b[1;32m     26\u001b[0m \u001b[39mreturn\u001b[39;00m branch\n",
      "Cell \u001b[0;32mIn[93], line 20\u001b[0m, in \u001b[0;36mlearn\u001b[0;34m(X, y, impurity_measure)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m Leaf(y[column]\u001b[39m.\u001b[39mvalue_counts()[\u001b[39m0\u001b[39m])\n\u001b[1;32m     18\u001b[0m \u001b[39m#find split with most information gain and split data to left and right branches\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m     split_index \u001b[39m=\u001b[39m information_gain(X,y)\n\u001b[1;32m     21\u001b[0m     split_key \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mkeys()[split_index]\n\u001b[1;32m     22\u001b[0m     split_value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(X[split_key])\n",
      "Cell \u001b[0;32mIn[88], line 5\u001b[0m, in \u001b[0;36minformation_gain\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m      3\u001b[0m data_entropy \u001b[39m=\u001b[39m calculate_data_entropy(y)\n\u001b[1;32m      4\u001b[0m \u001b[39m#calculate conditional entropy given a split data for each predictor\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m cond_entropy_array \u001b[39m=\u001b[39m calculate_conditional_entropy(X,y)\n\u001b[1;32m      6\u001b[0m \u001b[39m#difference in data set entropy and conditional entropies gives us information gain of each split\u001b[39;00m\n\u001b[1;32m      7\u001b[0m information_gain \u001b[39m=\u001b[39m data_entropy \u001b[39m-\u001b[39m cond_entropy_array\n",
      "Cell \u001b[0;32mIn[87], line 11\u001b[0m, in \u001b[0;36mcalculate_conditional_entropy\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m      9\u001b[0m     column \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mkeys()[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     10\u001b[0m     \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m y[column]\u001b[39m.\u001b[39munique():\n\u001b[0;32m---> 11\u001b[0m         prob_y_cond \u001b[39m=\u001b[39m (((X_split \u001b[39m==\u001b[39;49m value)\u001b[39m&\u001b[39;49m(y[column] \u001b[39m==\u001b[39;49m label))\u001b[39m.\u001b[39;49mvalue_counts()[\u001b[39mTrue\u001b[39;49;00m]\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(X_split))\u001b[39m/\u001b[39mprob_X\n\u001b[1;32m     12\u001b[0m         cond_entropy \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m prob_X \u001b[39m*\u001b[39m prob_y_cond \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mlog2(prob_y_cond)\n\u001b[1;32m     13\u001b[0m entropy_list\u001b[39m.\u001b[39mappend(cond_entropy)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m   1039\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1040\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m   1042\u001b[0m \u001b[39m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[39m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m \u001b[39mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1155\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1156\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1158\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1159\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: True"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"wine_dataset.csv\")\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1:]\n",
    "\n",
    "tree = learn(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
